{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 14pt;\">Prof. Krzysztof Rybinski</div><br/><br/>\n",
    "<div style=\"font-size: 22pt;\"><b>Artificial Intelligence course</b></div><br/><br/>\n",
    "<div style=\"font-size: 18pt;\">LAB 5</div><br/>\n",
    "<div style=\"font-size: 18pt;\">- Predicting handwritten digits in MNIST dataset with MLP</div><br/><br/>\n",
    "<div style=\"font-size: 18pt;\">- Homework 3 described at the end of this Jupyter Notebook</div><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:21:42.701445Z",
     "start_time": "2018-11-13T15:21:39.648435Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check MNIST data information\n",
    "# https://en.wikipedia.org/wiki/MNIST_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:29:02.781102Z",
     "start_time": "2018-11-13T15:29:02.369623Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = mnist.load_data()\n",
    "\n",
    "(Xtrain, ytrain), (Xtest, ytest) = dataset\n",
    "\n",
    "n_train = len(Xtrain)\n",
    "n_test = len(Xtest)\n",
    "\n",
    "n_features = 28*28\n",
    "\n",
    "Xtrain = Xtrain.reshape( n_train, n_features )\n",
    "Xtest  = Xtest.reshape( n_test, n_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:29:02.781102Z",
     "start_time": "2018-11-13T15:29:02.369623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAM4ElEQVR4nO3db6xU9Z3H8c9nWZoY6QNQce9alC7xgc3GgCIxQTfXkDYsPsBGuikPGjZpvH2Apo0NWeM+wIeN2bZZn5DcRlO6YW1IqEqMcSHYSBq18WJQLr0BkbBwyxVsMCmYGES/++AeN1ecc2acMzNn4Pt+JZOZOd85Z74Z7odz5vyZnyNCAK5+f9N0AwAGg7ADSRB2IAnCDiRB2IEk/naQb2abXf9An0WEW02vtWa3vdb2EdvHbD9WZ1kA+svdHme3PU/SUUnfljQt6U1JGyPiTxXzsGYH+qwfa/ZVko5FxPGIuCjpt5LW11gegD6qE/abJJ2a83y6mPYFtsdsT9ieqPFeAGqqs4Ou1abClzbTI2Jc0rjEZjzQpDpr9mlJS+Y8/4ak0/XaAdAvdcL+pqRbbX/T9tckfV/S7t60BaDXut6Mj4hLth+W9D+S5kl6JiIO96wzAD3V9aG3rt6M7+xA3/XlpBoAVw7CDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJdj88uSbZPSDov6VNJlyJiZS+aAtB7tcJeuC8i/tKD5QDoIzbjgSTqhj0k7bF9wPZYqxfYHrM9YXui5nsBqMER0f3M9t9HxGnbiyXtlfRIROyveH33bwagIxHhVtNrrdkj4nRxf1bSc5JW1VkegP7pOuy2r7X99c8fS/qOpMleNQagt+rsjb9R0nO2P1/Of0fEyz3pCkDP1frO/pXfjO/sQN/15Ts7gCsHYQeSIOxAEoQdSIKwA0n04kKYFDZs2FBae+ihhyrnPX36dGX9448/rqzv2LGjsv7++++X1o4dO1Y5L/JgzQ4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXDVW4eOHz9eWlu6dOngGmnh/PnzpbXDhw8PsJPhMj09XVp78sknK+edmLhyf0WNq96A5Ag7kARhB5Ig7EAShB1IgrADSRB2IAmuZ+9Q1TXrt99+e+W8U1NTlfXbbrutsn7HHXdU1kdHR0trd999d+W8p06dqqwvWbKksl7HpUuXKusffPBBZX1kZKTr9z558mRl/Uo+zl6GNTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMH17FeBhQsXltaWL19eOe+BAwcq63fddVc3LXWk3e/lHz16tLLe7vyFRYsWldY2b95cOe+2bdsq68Os6+vZbT9j+6ztyTnTFtnea/vd4r78rw3AUOhkM/7XktZeNu0xSfsi4lZJ+4rnAIZY27BHxH5J5y6bvF7S9uLxdkkP9LYtAL3W7bnxN0bEjCRFxIztxWUvtD0maazL9wHQI32/ECYixiWNS+ygA5rU7aG3M7ZHJKm4P9u7lgD0Q7dh3y1pU/F4k6QXetMOgH5pe5zd9rOSRiVdL+mMpK2Snpe0U9LNkk5K+l5EXL4Tr9Wy2IxHxx588MHK+s6dOyvrk5OTpbX77ruvct5z59r+OQ+tsuPsbb+zR8TGktKaWh0BGChOlwWSIOxAEoQdSIKwA0kQdiAJLnFFYxYvLj3LWpJ06NChWvNv2LChtLZr167Kea9kDNkMJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0kwZDMa0+7nnG+44YbK+ocfflhZP3LkyFfu6WrGmh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuB6dvTV6tWrS2uvvPJK5bzz58+vrI+OjlbW9+/fX1m/WnE9O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kwfXs6Kt169aV1todR9+3b19l/fXXX++qp6zartltP2P7rO3JOdOesP1n2weLW/m/KICh0Mlm/K8lrW0x/ZcRsby4vdTbtgD0WtuwR8R+SecG0AuAPqqzg+5h2+8Um/kLy15ke8z2hO2JGu8FoKZuw75N0jJJyyXNSPp52QsjYjwiVkbEyi7fC0APdBX2iDgTEZ9GxGeSfiVpVW/bAtBrXYXd9sicp9+VNFn2WgDDoe1xdtvPShqVdL3taUlbJY3aXi4pJJ2Q9KP+tYhhds0111TW165tdSBn1sWLFyvn3bp1a2X9k08+qazji9qGPSI2tpj8dB96AdBHnC4LJEHYgSQIO5AEYQeSIOxAElziilq2bNlSWV+xYkVp7eWXX66c97XXXuuqJ7TGmh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmDIZlS6//77K+vPP/98Zf2jjz4qrVVd/ipJb7zxRmUdrTFkM5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kwfXsyV133XWV9aeeeqqyPm/evMr6Sy+Vj/nJcfTBYs0OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwPftVrt1x8HbHuu+8887K+nvvvVdZr7pmvd286E7X17PbXmL797anbB+2/eNi+iLbe22/W9wv7HXTAHqnk834S5J+GhG3Sbpb0mbb35L0mKR9EXGrpH3FcwBDqm3YI2ImIt4qHp+XNCXpJknrJW0vXrZd0gN96hFAD3ylc+NtL5W0QtIfJd0YETPS7H8ItheXzDMmaaxmnwBq6jjsthdI2iXpJxHxV7vlPoAviYhxSePFMthBBzSko0NvtudrNug7IuJ3xeQztkeK+oiks/1pEUAvtF2ze3YV/rSkqYj4xZzSbkmbJP2suH+hLx2ilmXLllXW2x1aa+fRRx+trHN4bXh0shm/WtIPJB2yfbCY9rhmQ77T9g8lnZT0vb50CKAn2oY9Iv4gqewL+pretgOgXzhdFkiCsANJEHYgCcIOJEHYgST4KemrwC233FJa27NnT61lb9mypbL+4osv1lo+Boc1O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXH2q8DYWPmvft188821lv3qq69W1gf5U+SohzU7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBcfYrwD333FNZf+SRRwbUCa5krNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIlOxmdfIuk3kv5O0meSxiPiP20/IekhSR8UL308Il7qV6OZ3XvvvZX1BQsWdL3sduOnX7hwoetlY7h0clLNJUk/jYi3bH9d0gHbe4vaLyPiP/rXHoBe6WR89hlJM8Xj87anJN3U78YA9NZX+s5ue6mkFZL+WEx62PY7tp+xvbBknjHbE7Yn6rUKoI6Ow257gaRdkn4SEX+VtE3SMknLNbvm/3mr+SJiPCJWRsTK+u0C6FZHYbc9X7NB3xERv5OkiDgTEZ9GxGeSfiVpVf/aBFBX27DbtqSnJU1FxC/mTB+Z87LvSprsfXsAeqWTvfGrJf1A0iHbB4tpj0vaaHu5pJB0QtKP+tAfanr77bcr62vWrKmsnzt3rpftoEGd7I3/gyS3KHFMHbiCcAYdkARhB5Ig7EAShB1IgrADSRB2IAkPcshd24zvC/RZRLQ6VM6aHciCsANJEHYgCcIOJEHYgSQIO5AEYQeSGPSQzX+R9L9znl9fTBtGw9rbsPYl0Vu3etnbLWWFgZ5U86U3tyeG9bfphrW3Ye1LorduDao3NuOBJAg7kETTYR9v+P2rDGtvw9qXRG/dGkhvjX5nBzA4Ta/ZAQwIYQeSaCTsttfaPmL7mO3HmuihjO0Ttg/ZPtj0+HTFGHpnbU/OmbbI9l7b7xb3LcfYa6i3J2z/ufjsDtpe11BvS2z/3vaU7cO2f1xMb/Szq+hrIJ/bwL+z254n6aikb0ualvSmpI0R8aeBNlLC9glJKyOi8RMwbP+TpAuSfhMR/1hMe1LSuYj4WfEf5cKI+Lch6e0JSReaHsa7GK1oZO4w45IekPSvavCzq+jrXzSAz62JNfsqScci4nhEXJT0W0nrG+hj6EXEfkmXD8myXtL24vF2zf6xDFxJb0MhImYi4q3i8XlJnw8z3uhnV9HXQDQR9psknZrzfFrDNd57SNpj+4DtsaabaeHGiJiRZv94JC1uuJ/LtR3Ge5AuG2Z8aD67boY/r6uJsLf6faxhOv63OiLukPTPkjYXm6voTEfDeA9Ki2HGh0K3w5/X1UTYpyUtmfP8G5JON9BHSxFxurg/K+k5Dd9Q1Gc+H0G3uD/bcD//b5iG8W41zLiG4LNrcvjzJsL+pqRbbX/T9tckfV/S7gb6+BLb1xY7TmT7Wknf0fANRb1b0qbi8SZJLzTYyxcMyzDeZcOMq+HPrvHhzyNi4DdJ6zS7R/49Sf/eRA8lff2DpLeL2+Gme5P0rGY36z7R7BbRDyVdJ2mfpHeL+0VD1Nt/STok6R3NBmukod7u0exXw3ckHSxu65r+7Cr6GsjnxumyQBKcQQckQdiBJAg7kARhB5Ig7EAShB1IgrADSfwfrLwRQB25h+kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( np.reshape( Xtest[0], (28,28) ) , cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:29:02.787949Z",
     "start_time": "2018-11-13T15:29:02.783514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:29:17.565311Z",
     "start_time": "2018-11-13T15:29:17.559317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:29:32.437992Z",
     "start_time": "2018-11-13T15:29:32.433262Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:45:27.566378Z",
     "start_time": "2018-11-13T15:45:27.562418Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100,50), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check info on MLPClassifer in sklearn\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:46:02.148932Z",
     "start_time": "2018-11-13T15:45:28.037088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.17073142\n",
      "Iteration 2, loss = 0.26492316\n",
      "Iteration 3, loss = 0.18511654\n",
      "Iteration 4, loss = 0.14232035\n",
      "Iteration 5, loss = 0.11684591\n",
      "Iteration 6, loss = 0.09706454\n",
      "Iteration 7, loss = 0.08338486\n",
      "Iteration 8, loss = 0.07412029\n",
      "Iteration 9, loss = 0.06945792\n",
      "Iteration 10, loss = 0.06637395\n",
      "Iteration 11, loss = 0.06124470\n",
      "Iteration 12, loss = 0.05564527\n",
      "Iteration 13, loss = 0.05375233\n",
      "Iteration 14, loss = 0.05480617\n",
      "Iteration 15, loss = 0.05756312\n",
      "Iteration 16, loss = 0.04612014\n",
      "Iteration 17, loss = 0.04026130\n",
      "Iteration 18, loss = 0.03935366\n",
      "Iteration 19, loss = 0.03556915\n",
      "Iteration 20, loss = 0.03391190\n",
      "Iteration 21, loss = 0.03468409\n",
      "Iteration 22, loss = 0.03423417\n",
      "Iteration 23, loss = 0.03952561\n",
      "Iteration 24, loss = 0.03081623\n",
      "Iteration 25, loss = 0.02612753\n",
      "Iteration 26, loss = 0.03089620\n",
      "Iteration 27, loss = 0.02426175\n",
      "Iteration 28, loss = 0.02743028\n",
      "Iteration 29, loss = 0.02677722\n",
      "Iteration 30, loss = 0.01729159\n",
      "Iteration 31, loss = 0.02315419\n",
      "Iteration 32, loss = 0.02607682\n",
      "Iteration 33, loss = 0.02422786\n",
      "Iteration 34, loss = 0.01563106\n",
      "Iteration 35, loss = 0.02169400\n",
      "Iteration 36, loss = 0.02338827\n",
      "Iteration 37, loss = 0.01665400\n",
      "Iteration 38, loss = 0.01501038\n",
      "Iteration 39, loss = 0.02646297\n",
      "Iteration 40, loss = 0.02122941\n",
      "Iteration 41, loss = 0.01845175\n",
      "Iteration 42, loss = 0.01321811\n",
      "Iteration 43, loss = 0.01889020\n",
      "Iteration 44, loss = 0.01703732\n",
      "Iteration 45, loss = 0.01651771\n",
      "Iteration 46, loss = 0.01604495\n",
      "Iteration 47, loss = 0.01764010\n",
      "Iteration 48, loss = 0.01032839\n",
      "Iteration 49, loss = 0.01028954\n",
      "Iteration 50, loss = 0.00996099\n",
      "Iteration 51, loss = 0.01679694\n",
      "Iteration 52, loss = 0.01072311\n",
      "Iteration 53, loss = 0.01515044\n",
      "Iteration 54, loss = 0.01750390\n",
      "Iteration 55, loss = 0.01474109\n",
      "Iteration 56, loss = 0.01287480\n",
      "Iteration 57, loss = 0.01533775\n",
      "Iteration 58, loss = 0.00828865\n",
      "Iteration 59, loss = 0.01140185\n",
      "Iteration 60, loss = 0.01226019\n",
      "Iteration 61, loss = 0.01020215\n",
      "Iteration 62, loss = 0.01516083\n",
      "Iteration 63, loss = 0.00754564\n",
      "Iteration 64, loss = 0.00866937\n",
      "Iteration 65, loss = 0.00749365\n",
      "Iteration 66, loss = 0.01462406\n",
      "Iteration 67, loss = 0.01158846\n",
      "Iteration 68, loss = 0.01199232\n",
      "Iteration 69, loss = 0.00585647\n",
      "Iteration 70, loss = 0.00758559\n",
      "Iteration 71, loss = 0.01062623\n",
      "Iteration 72, loss = 0.01594353\n",
      "Iteration 73, loss = 0.00754036\n",
      "Iteration 74, loss = 0.00649420\n",
      "Iteration 75, loss = 0.00860761\n",
      "Iteration 76, loss = 0.00919106\n",
      "Iteration 77, loss = 0.01852110\n",
      "Iteration 78, loss = 0.00655999\n",
      "Iteration 79, loss = 0.00477355\n",
      "Iteration 80, loss = 0.01107848\n",
      "Iteration 81, loss = 0.00940365\n",
      "Iteration 82, loss = 0.00728234\n",
      "Iteration 83, loss = 0.01337955\n",
      "Iteration 84, loss = 0.00558373\n",
      "Iteration 85, loss = 0.00966915\n",
      "Iteration 86, loss = 0.00550682\n",
      "Iteration 87, loss = 0.00613263\n",
      "Iteration 88, loss = 0.00980576\n",
      "Iteration 89, loss = 0.01199828\n",
      "Iteration 90, loss = 0.00985676\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 100, 100, 50), verbose=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on MLPClassifier in module sklearn.neural_network._multilayer_perceptron object:\n",
      "\n",
      "class MLPClassifier(sklearn.base.ClassifierMixin, BaseMultilayerPerceptron)\n",
      " |  MLPClassifier(hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |  \n",
      " |  Multi-layer Perceptron classifier.\n",
      " |  \n",
      " |  This model optimizes the log-loss function using LBFGS or stochastic\n",
      " |  gradient descent.\n",
      " |  \n",
      " |  .. versionadded:: 0.18\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  hidden_layer_sizes : tuple, length = n_layers - 2, default=(100,)\n",
      " |      The ith element represents the number of neurons in the ith\n",
      " |      hidden layer.\n",
      " |  \n",
      " |  activation : {'identity', 'logistic', 'tanh', 'relu'}, default='relu'\n",
      " |      Activation function for the hidden layer.\n",
      " |  \n",
      " |      - 'identity', no-op activation, useful to implement linear bottleneck,\n",
      " |        returns f(x) = x\n",
      " |  \n",
      " |      - 'logistic', the logistic sigmoid function,\n",
      " |        returns f(x) = 1 / (1 + exp(-x)).\n",
      " |  \n",
      " |      - 'tanh', the hyperbolic tan function,\n",
      " |        returns f(x) = tanh(x).\n",
      " |  \n",
      " |      - 'relu', the rectified linear unit function,\n",
      " |        returns f(x) = max(0, x)\n",
      " |  \n",
      " |  solver : {'lbfgs', 'sgd', 'adam'}, default='adam'\n",
      " |      The solver for weight optimization.\n",
      " |  \n",
      " |      - 'lbfgs' is an optimizer in the family of quasi-Newton methods.\n",
      " |  \n",
      " |      - 'sgd' refers to stochastic gradient descent.\n",
      " |  \n",
      " |      - 'adam' refers to a stochastic gradient-based optimizer proposed\n",
      " |        by Kingma, Diederik, and Jimmy Ba\n",
      " |  \n",
      " |      Note: The default solver 'adam' works pretty well on relatively\n",
      " |      large datasets (with thousands of training samples or more) in terms of\n",
      " |      both training time and validation score.\n",
      " |      For small datasets, however, 'lbfgs' can converge faster and perform\n",
      " |      better.\n",
      " |  \n",
      " |  alpha : float, default=0.0001\n",
      " |      L2 penalty (regularization term) parameter.\n",
      " |  \n",
      " |  batch_size : int, default='auto'\n",
      " |      Size of minibatches for stochastic optimizers.\n",
      " |      If the solver is 'lbfgs', the classifier will not use minibatch.\n",
      " |      When set to \"auto\", `batch_size=min(200, n_samples)`.\n",
      " |  \n",
      " |  learning_rate : {'constant', 'invscaling', 'adaptive'}, default='constant'\n",
      " |      Learning rate schedule for weight updates.\n",
      " |  \n",
      " |      - 'constant' is a constant learning rate given by\n",
      " |        'learning_rate_init'.\n",
      " |  \n",
      " |      - 'invscaling' gradually decreases the learning rate at each\n",
      " |        time step 't' using an inverse scaling exponent of 'power_t'.\n",
      " |        effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
      " |  \n",
      " |      - 'adaptive' keeps the learning rate constant to\n",
      " |        'learning_rate_init' as long as training loss keeps decreasing.\n",
      " |        Each time two consecutive epochs fail to decrease training loss by at\n",
      " |        least tol, or fail to increase validation score by at least tol if\n",
      " |        'early_stopping' is on, the current learning rate is divided by 5.\n",
      " |  \n",
      " |      Only used when ``solver='sgd'``.\n",
      " |  \n",
      " |  learning_rate_init : float, default=0.001\n",
      " |      The initial learning rate used. It controls the step-size\n",
      " |      in updating the weights. Only used when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  power_t : float, default=0.5\n",
      " |      The exponent for inverse scaling learning rate.\n",
      " |      It is used in updating effective learning rate when the learning_rate\n",
      " |      is set to 'invscaling'. Only used when solver='sgd'.\n",
      " |  \n",
      " |  max_iter : int, default=200\n",
      " |      Maximum number of iterations. The solver iterates until convergence\n",
      " |      (determined by 'tol') or this number of iterations. For stochastic\n",
      " |      solvers ('sgd', 'adam'), note that this determines the number of epochs\n",
      " |      (how many times each data point will be used), not the number of\n",
      " |      gradient steps.\n",
      " |  \n",
      " |  shuffle : bool, default=True\n",
      " |      Whether to shuffle samples in each iteration. Only used when\n",
      " |      solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Determines random number generation for weights and bias\n",
      " |      initialization, train-test split if early stopping is used, and batch\n",
      " |      sampling when solver='sgd' or 'adam'.\n",
      " |      Pass an int for reproducible results across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the optimization. When the loss or score is not improving\n",
      " |      by at least ``tol`` for ``n_iter_no_change`` consecutive iterations,\n",
      " |      unless ``learning_rate`` is set to 'adaptive', convergence is\n",
      " |      considered to be reached and training stops.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Whether to print progress messages to stdout.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous\n",
      " |      call to fit as initialization, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  momentum : float, default=0.9\n",
      " |      Momentum for gradient descent update. Should be between 0 and 1. Only\n",
      " |      used when solver='sgd'.\n",
      " |  \n",
      " |  nesterovs_momentum : bool, default=True\n",
      " |      Whether to use Nesterov's momentum. Only used when solver='sgd' and\n",
      " |      momentum > 0.\n",
      " |  \n",
      " |  early_stopping : bool, default=False\n",
      " |      Whether to use early stopping to terminate training when validation\n",
      " |      score is not improving. If set to true, it will automatically set\n",
      " |      aside 10% of training data as validation and terminate training when\n",
      " |      validation score is not improving by at least tol for\n",
      " |      ``n_iter_no_change`` consecutive epochs. The split is stratified,\n",
      " |      except in a multilabel setting.\n",
      " |      If early stopping is False, then the training stops when the training\n",
      " |      loss does not improve by more than tol for n_iter_no_change consecutive\n",
      " |      passes over the training set.\n",
      " |      Only effective when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True.\n",
      " |  \n",
      " |  beta_1 : float, default=0.9\n",
      " |      Exponential decay rate for estimates of first moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'.\n",
      " |  \n",
      " |  beta_2 : float, default=0.999\n",
      " |      Exponential decay rate for estimates of second moment vector in adam,\n",
      " |      should be in [0, 1). Only used when solver='adam'.\n",
      " |  \n",
      " |  epsilon : float, default=1e-8\n",
      " |      Value for numerical stability in adam. Only used when solver='adam'.\n",
      " |  \n",
      " |  n_iter_no_change : int, default=10\n",
      " |      Maximum number of epochs to not meet ``tol`` improvement.\n",
      " |      Only effective when solver='sgd' or 'adam'.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  max_fun : int, default=15000\n",
      " |      Only used when solver='lbfgs'. Maximum number of loss function calls.\n",
      " |      The solver iterates until convergence (determined by 'tol'), number\n",
      " |      of iterations reaches max_iter, or this number of loss function calls.\n",
      " |      Note that number of loss function calls will be greater than or equal\n",
      " |      to the number of iterations for the `MLPClassifier`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : ndarray or list of ndarray of shape (n_classes,)\n",
      " |      Class labels for each output.\n",
      " |  \n",
      " |  loss_ : float\n",
      " |      The current loss computed with the loss function.\n",
      " |  \n",
      " |  best_loss_ : float\n",
      " |      The minimum loss reached by the solver throughout fitting.\n",
      " |  \n",
      " |  loss_curve_ : list of shape (`n_iter_`,)\n",
      " |      The ith element in the list represents the loss at the ith iteration.\n",
      " |  \n",
      " |  t_ : int\n",
      " |      The number of training samples seen by the solver during fitting.\n",
      " |  \n",
      " |  coefs_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the weight matrix corresponding\n",
      " |      to layer i.\n",
      " |  \n",
      " |  intercepts_ : list of shape (n_layers - 1,)\n",
      " |      The ith element in the list represents the bias vector corresponding to\n",
      " |      layer i + 1.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      The number of iterations the solver has run.\n",
      " |  \n",
      " |  n_layers_ : int\n",
      " |      Number of layers.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      Number of outputs.\n",
      " |  \n",
      " |  out_activation_ : str\n",
      " |      Name of the output activation function.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  MLPRegressor : Multi-layer Perceptron regressor.\n",
      " |  BernoulliRBM : Bernoulli Restricted Boltzmann Machine (RBM).\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  MLPClassifier trains iteratively since at each time step\n",
      " |  the partial derivatives of the loss function with respect to the model\n",
      " |  parameters are computed to update the parameters.\n",
      " |  \n",
      " |  It can also have a regularization term added to the loss function\n",
      " |  that shrinks model parameters to prevent overfitting.\n",
      " |  \n",
      " |  This implementation works with data represented as dense numpy arrays or\n",
      " |  sparse scipy arrays of floating point values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Hinton, Geoffrey E.\n",
      " |      \"Connectionist learning procedures.\" Artificial intelligence 40.1\n",
      " |      (1989): 185-234.\n",
      " |  \n",
      " |  Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of\n",
      " |      training deep feedforward neural networks.\" International Conference\n",
      " |      on Artificial Intelligence and Statistics. 2010.\n",
      " |  \n",
      " |  He, Kaiming, et al. \"Delving deep into rectifiers: Surpassing human-level\n",
      " |      performance on imagenet classification.\" arXiv preprint\n",
      " |      arXiv:1502.01852 (2015).\n",
      " |  \n",
      " |  Kingma, Diederik, and Jimmy Ba. \"Adam: A method for stochastic\n",
      " |      optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.neural_network import MLPClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> from sklearn.model_selection import train_test_split\n",
      " |  >>> X, y = make_classification(n_samples=100, random_state=1)\n",
      " |  >>> X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
      " |  ...                                                     random_state=1)\n",
      " |  >>> clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\n",
      " |  >>> clf.predict_proba(X_test[:1])\n",
      " |  array([[0.038..., 0.961...]])\n",
      " |  >>> clf.predict(X_test[:5, :])\n",
      " |  array([1, 0, 1, 0, 1])\n",
      " |  >>> clf.score(X_test, y_test)\n",
      " |  0.8...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MLPClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseMultilayerPerceptron\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  partial_fit(self, X, y, classes=None)\n",
      " |      Update the model with a single iteration over the given data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      classes : array of shape (n_classes,), default=None\n",
      " |          Classes across all calls to partial_fit.\n",
      " |          Can be obtained via `np.unique(y_all)`, where y_all is the\n",
      " |          target vector of the entire dataset.\n",
      " |          This argument is required for the first call to partial_fit\n",
      " |          and can be omitted in the subsequent calls.\n",
      " |          Note that y doesn't need to contain all labels in `classes`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Trained MLP model.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the multi-layer perceptron classifier.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray, shape (n_samples,) or (n_samples, n_classes)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return the log of probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      log_y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted log-probability of the sample for each class\n",
      " |          in the model, where classes are ordered as they are in\n",
      " |          `self.classes_`. Equivalent to `log(predict_proba(X))`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_prob : ndarray of shape (n_samples, n_classes)\n",
      " |          The predicted probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in `self.classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseMultilayerPerceptron:\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the model to data matrix X and target(s) y.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray or sparse matrix of shape (n_samples, n_features)\n",
      " |          The input data.\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns a trained MLP model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3.86372561e-315, -1.19956143e-315, -1.55869696e-315, ...,\n",
      "         1.52258412e-315,  3.30999263e-315,  3.15261144e-316],\n",
      "       [ 1.83864745e-315, -1.60575006e-315,  4.28965886e-316, ...,\n",
      "        -4.50060219e-315, -3.38680628e-315,  1.35486125e-316],\n",
      "       [-1.39163813e-315,  2.31137259e-315, -3.81786058e-315, ...,\n",
      "        -1.96489364e-317,  1.80323062e-315,  3.67905158e-316],\n",
      "       ...,\n",
      "       [ 2.12441562e-315,  9.71556298e-316,  2.37929468e-315, ...,\n",
      "        -3.67776281e-315, -9.12624128e-316,  5.36933370e-316],\n",
      "       [-4.07917010e-315,  4.90685012e-316,  1.19329200e-315, ...,\n",
      "        -1.21291304e-315,  4.36708231e-316, -5.36622316e-316],\n",
      "       [-4.79372233e-315,  4.49874313e-315, -1.16186026e-315, ...,\n",
      "         2.82224718e-315,  2.99739400e-316,  1.28785569e-315]]), array([[-1.79757427e-01,  4.24726665e-02,  2.91924601e-02,\n",
      "        -8.70623398e-02,  2.24965209e-02,  1.10574253e-03,\n",
      "         3.85125679e-03,  1.33512810e-01,  1.56574283e-01,\n",
      "        -7.55194982e-02],\n",
      "       [-9.36334763e-02,  7.22410283e-02, -1.42054712e-01,\n",
      "         1.92166149e-02, -8.82292885e-02,  7.33706687e-02,\n",
      "         2.05463891e-02,  5.73104425e-02, -1.07781373e-01,\n",
      "        -2.18615023e-02],\n",
      "       [-2.34052923e-02,  3.00962861e-02,  1.13835842e-01,\n",
      "         5.81041018e-02,  6.85341903e-02,  4.76623724e-02,\n",
      "        -2.87056471e-02, -9.00787629e-02, -2.88010051e-02,\n",
      "        -2.77795556e-02],\n",
      "       [ 1.22804405e-01, -8.61362498e-02,  1.15645230e-01,\n",
      "         2.78796599e-02,  7.46208782e-02,  1.54453173e-01,\n",
      "        -6.40750199e-02,  2.27942972e-01,  7.64729831e-02,\n",
      "         1.37244422e-01],\n",
      "       [ 8.75871602e-03, -6.75746958e-03, -1.46976153e-02,\n",
      "        -3.46573030e-02, -1.04209161e-01,  1.92446892e-02,\n",
      "         9.09875890e-02,  5.51539889e-02,  5.73678121e-02,\n",
      "        -1.72317325e-01],\n",
      "       [ 1.00107827e-01,  1.77163428e-01,  6.86270549e-02,\n",
      "        -1.95460260e-01,  1.96469222e-03, -1.29654819e-01,\n",
      "        -7.11394542e-02,  8.31823090e-02,  4.52990681e-02,\n",
      "        -1.03304386e-01],\n",
      "       [ 6.51596933e-02,  1.03935973e-01, -2.19267455e-02,\n",
      "        -3.08441050e-02,  2.16007588e-02,  5.05306801e-02,\n",
      "         1.11955205e-01,  7.97757275e-02,  1.30337398e-02,\n",
      "        -9.47839356e-02],\n",
      "       [-2.25108354e-01, -4.93700555e-02,  5.01624059e-03,\n",
      "        -3.71891986e-02, -5.72338514e-02, -9.39663013e-02,\n",
      "        -9.92578323e-02, -9.65987249e-02,  6.79572555e-03,\n",
      "        -2.04673459e-04],\n",
      "       [ 1.16262965e-01, -1.54436038e-02, -2.15747793e-02,\n",
      "        -1.56239582e-01,  5.60197552e-02, -1.34886403e-01,\n",
      "        -1.63650989e-01, -1.31698050e-01,  7.33848401e-02,\n",
      "        -1.24382947e-01],\n",
      "       [-3.14825853e-02, -1.60342742e-01, -4.17702890e-02,\n",
      "         5.33033836e-02, -8.51656537e-03,  1.27605222e-01,\n",
      "         1.40689805e-01, -4.53842296e-02,  7.36070959e-02,\n",
      "         4.42029408e-02],\n",
      "       [ 9.15303000e-02, -8.70195985e-02,  1.12111014e-01,\n",
      "         2.40812867e-02,  1.02494948e-01, -5.54215006e-05,\n",
      "         9.27013994e-02, -3.13938005e-02,  3.42658142e-02,\n",
      "         4.90793703e-02],\n",
      "       [ 4.96454693e-02,  7.27610522e-02, -8.83581656e-02,\n",
      "         6.12022951e-02, -4.87351374e-03,  9.65567100e-02,\n",
      "        -7.28276331e-02,  6.79537080e-02,  8.63080648e-02,\n",
      "         7.14044169e-02],\n",
      "       [ 7.15902853e-02,  1.48967409e-01,  1.70379999e-01,\n",
      "         9.64332076e-02,  3.00480140e-02,  2.93372206e-02,\n",
      "         8.40757194e-02,  1.44036923e-01,  6.75412002e-02,\n",
      "        -1.84661012e-01],\n",
      "       [-1.39714176e-01, -6.19166629e-02, -1.06181926e-01,\n",
      "         4.86569698e-02, -1.40167551e-01, -1.36015432e-02,\n",
      "        -5.19215075e-02, -1.35000645e-01,  5.19535118e-03,\n",
      "        -7.99969685e-02],\n",
      "       [ 9.25739489e-02, -4.92098888e-02,  7.35951917e-02,\n",
      "         9.83581272e-03, -2.10763711e-01,  2.88920815e-02,\n",
      "        -4.41918591e-03, -3.40351819e-03, -2.04677279e-03,\n",
      "         2.53967248e-02],\n",
      "       [-3.18294139e-02, -1.69252186e-01,  2.07903003e-01,\n",
      "         3.54689671e-02, -7.32867253e-02, -1.04054955e-01,\n",
      "         1.02126367e-03, -1.12029927e-01, -1.23773390e-01,\n",
      "         1.91991294e-01],\n",
      "       [-3.88924368e-02,  1.24656420e-01,  1.41020794e-01,\n",
      "         3.59473151e-02,  3.72612401e-02,  3.05129340e-02,\n",
      "        -3.47892420e-02,  1.30867608e-01, -2.52011226e-02,\n",
      "         9.14517620e-02],\n",
      "       [ 4.97201314e-02,  6.99092053e-02,  3.84013516e-02,\n",
      "         6.21138695e-02, -1.90017792e-02,  1.59167945e-01,\n",
      "         1.47026463e-02, -4.57456771e-02,  5.52116324e-02,\n",
      "         2.34896211e-02],\n",
      "       [ 1.18245601e-01, -1.68930805e-01, -5.44171732e-02,\n",
      "         6.34619149e-02,  5.84481235e-02, -3.30546130e-02,\n",
      "         9.46732231e-02,  4.88780681e-02, -7.78614033e-03,\n",
      "         1.28565782e-01],\n",
      "       [ 9.94128257e-02,  5.69343274e-02, -4.68324139e-03,\n",
      "        -5.35791890e-02,  6.39983218e-02, -3.62307263e-02,\n",
      "        -8.25640223e-02, -3.52969935e-02,  2.42522026e-02,\n",
      "        -4.31629751e-02],\n",
      "       [-2.43114359e-02,  3.91975845e-02,  7.85978652e-02,\n",
      "         8.10599564e-02, -1.47830593e-02, -6.09719265e-03,\n",
      "        -1.20498612e-01,  1.04191917e-01,  6.06897678e-02,\n",
      "         7.18890904e-02],\n",
      "       [-4.26321209e-02,  9.54089000e-02, -4.13979988e-02,\n",
      "        -1.73041465e-01, -1.00199662e-01,  1.73303233e-01,\n",
      "         1.81822127e-01,  1.80955940e-02,  1.47711730e-01,\n",
      "         2.85837231e-02],\n",
      "       [ 1.22944805e-01, -8.32250048e-02, -1.57343030e-02,\n",
      "         1.14502222e-01,  3.53545499e-02,  4.83819931e-03,\n",
      "        -9.63340954e-02, -2.41999227e-02, -6.65924169e-02,\n",
      "        -1.77244615e-01],\n",
      "       [ 7.65002303e-02, -2.03022105e-01, -1.45456518e-01,\n",
      "        -1.33858201e-01, -7.07044756e-02, -4.65950236e-02,\n",
      "        -8.33604482e-02,  1.04447556e-03, -8.40825601e-02,\n",
      "         9.06136720e-02],\n",
      "       [-1.12946272e-01,  5.76813466e-02,  1.00920091e-01,\n",
      "        -3.30566910e-02, -2.30400026e-02, -1.02472748e-01,\n",
      "         6.81334320e-02,  6.85925994e-02,  6.57522874e-02,\n",
      "         6.68512817e-02],\n",
      "       [-1.01878154e-01,  2.49277525e-02,  1.59890322e-02,\n",
      "         7.86527027e-02,  4.11545260e-03,  6.92050324e-02,\n",
      "        -9.28559476e-02, -5.25931738e-03,  1.13379730e-02,\n",
      "         6.05669598e-02],\n",
      "       [-6.00867451e-02,  1.17223545e-01,  1.06057278e-01,\n",
      "         3.14434745e-02,  1.76609154e-01, -2.09634012e-02,\n",
      "        -8.68244171e-03,  9.93095863e-02, -1.54152655e-02,\n",
      "         1.98718457e-02],\n",
      "       [ 3.43877402e-02, -1.84225587e-01, -5.40527538e-02,\n",
      "        -2.01860469e-03, -7.95232582e-02,  8.50939476e-02,\n",
      "        -6.20481934e-02, -6.60324187e-03,  4.23490647e-03,\n",
      "        -1.77936103e-02],\n",
      "       [-9.20416851e-02, -3.09059088e-02,  2.54047653e-02,\n",
      "         8.90580770e-02,  6.87407365e-02,  5.91517911e-02,\n",
      "         1.66598728e-01, -1.09012185e-02,  5.34244421e-03,\n",
      "         1.00317138e-02],\n",
      "       [ 2.00145866e-03,  9.44296365e-02, -1.09431492e-02,\n",
      "         6.17652379e-03,  1.22212037e-01,  1.51871816e-02,\n",
      "         9.94198487e-02, -1.37711239e-02,  3.18335716e-02,\n",
      "        -2.98773928e-02],\n",
      "       [-1.12098712e-02,  2.48582613e-04,  1.08274391e-01,\n",
      "        -3.35339010e-02, -1.16157611e-01,  1.25088155e-02,\n",
      "        -3.84539326e-02, -1.15388746e-01,  1.19961679e-01,\n",
      "        -5.86015101e-02],\n",
      "       [-5.06026957e-02, -7.98315695e-02,  1.12093722e-02,\n",
      "         1.15131855e-01, -2.07037347e-01,  5.54918570e-02,\n",
      "        -1.32899162e-01,  6.57940411e-03, -1.58989004e-01,\n",
      "        -5.55345325e-02],\n",
      "       [-6.44724794e-02,  3.14776116e-02, -2.28529182e-02,\n",
      "         1.02501961e-01,  4.86611065e-03,  1.94872932e-02,\n",
      "        -5.71312320e-02,  5.78411141e-02, -2.37262326e-02,\n",
      "        -6.26494048e-02],\n",
      "       [ 6.29930321e-02,  1.80730150e-01, -4.45812858e-02,\n",
      "        -9.11389825e-02,  2.90733555e-02,  1.32976559e-02,\n",
      "        -9.71521317e-03, -1.32032703e-01, -1.06340232e-01,\n",
      "         1.54256660e-01],\n",
      "       [ 1.23007348e-01,  4.18578187e-02,  9.91426825e-02,\n",
      "         5.62903183e-02, -2.66516845e-03,  2.41717336e-03,\n",
      "        -6.00650838e-02, -7.64919491e-02, -3.45404985e-02,\n",
      "        -3.53862324e-02],\n",
      "       [ 6.56909342e-05, -6.42602022e-02,  8.07351033e-02,\n",
      "        -1.64037191e-02, -5.19158636e-02, -9.02449591e-02,\n",
      "         4.42593789e-04,  5.78599955e-02, -1.48733105e-02,\n",
      "        -1.19753638e-01],\n",
      "       [-1.97351222e-03,  1.04095194e-01, -1.14189242e-02,\n",
      "         1.27481048e-01,  1.69065104e-01,  8.87925729e-02,\n",
      "        -1.65132565e-01,  1.85140443e-01,  1.74331482e-02,\n",
      "         8.66760120e-02],\n",
      "       [-9.81344059e-02,  7.54357703e-02,  1.06692235e-01,\n",
      "         7.19468505e-02,  1.21055810e-01,  1.98247635e-01,\n",
      "        -1.01029966e-01,  1.96393411e-02, -4.25280365e-02,\n",
      "         1.05243699e-01],\n",
      "       [-4.65530870e-02, -8.27160713e-02, -1.28405028e-02,\n",
      "         2.28849137e-02,  6.58382658e-02,  6.21797670e-02,\n",
      "        -2.38844801e-05, -4.63625569e-03,  8.98404326e-02,\n",
      "         6.03561913e-02],\n",
      "       [-1.19427104e-01,  1.41085402e-01,  2.75408924e-02,\n",
      "         6.73671195e-02,  1.52665553e-01,  1.36749386e-02,\n",
      "        -1.46264164e-03,  1.45524382e-01,  1.47973996e-02,\n",
      "         1.53410713e-01],\n",
      "       [ 2.99374692e-02, -4.39544802e-02,  2.51333798e-02,\n",
      "         5.28987100e-02, -5.47342756e-02,  1.99744543e-02,\n",
      "         4.79866462e-02, -1.34925429e-01,  8.71828349e-03,\n",
      "        -1.29474168e-01],\n",
      "       [-5.85404764e-02,  1.65783132e-03,  1.37657238e-02,\n",
      "         1.12480418e-02, -1.23503575e-01, -6.35224179e-03,\n",
      "        -5.35858991e-02, -1.84315118e-01,  7.95723183e-02,\n",
      "        -4.09486569e-02],\n",
      "       [ 4.17473696e-02,  5.86432992e-02,  1.39655980e-01,\n",
      "         1.22795888e-01, -7.95321355e-02,  6.80400383e-02,\n",
      "        -2.44216830e-02,  1.20122024e-01,  8.94504275e-02,\n",
      "        -1.82991755e-02],\n",
      "       [ 1.16676293e-01, -1.26641511e-01, -2.33211576e-02,\n",
      "        -1.83244439e-01,  8.00496681e-02,  1.51214823e-01,\n",
      "         1.09480218e-01, -1.16440331e-01, -7.81606540e-02,\n",
      "         1.24406302e-01],\n",
      "       [-3.50632733e-02, -2.25758050e-02, -2.21097572e-02,\n",
      "        -4.28873105e-02,  2.54007907e-02,  7.66614062e-02,\n",
      "         9.15185099e-02, -3.80079907e-02,  5.38926714e-02,\n",
      "         3.28402154e-02],\n",
      "       [-1.37057925e-01, -1.29032482e-01,  1.52173211e-01,\n",
      "        -3.40953642e-02, -1.86897195e-01,  2.00065777e-01,\n",
      "         1.62301349e-01, -7.85372357e-03, -6.77781027e-02,\n",
      "         1.43438997e-01],\n",
      "       [-9.74603365e-02,  1.09865499e-01, -5.89848411e-02,\n",
      "        -1.06163160e-01,  2.67670929e-02, -1.65209524e-02,\n",
      "        -6.63793897e-02,  6.09775316e-03,  3.49169406e-02,\n",
      "         5.93577011e-02],\n",
      "       [-1.49131409e-02, -3.06554654e-02,  8.16233636e-02,\n",
      "         1.76514912e-02,  1.13495712e-01,  3.36402245e-02,\n",
      "        -6.35230844e-02, -4.11358212e-02, -2.91020579e-02,\n",
      "        -2.40851652e-02],\n",
      "       [ 3.76807071e-02, -3.09287837e-02,  4.63813851e-02,\n",
      "         1.01691567e-01,  1.01000751e-01,  4.34332908e-02,\n",
      "         1.35922595e-02,  1.04628657e-01, -4.42944146e-02,\n",
      "         1.33477315e-01],\n",
      "       [-1.72164360e-02,  1.43375321e-02,  1.52310179e-01,\n",
      "        -6.64476802e-03,  8.48672853e-02,  5.74423293e-02,\n",
      "        -2.66426917e-02, -1.08900937e-01, -2.97723738e-02,\n",
      "        -8.30940709e-02],\n",
      "       [-2.32755893e-02, -3.93168205e-02, -1.25524218e-01,\n",
      "        -8.30363647e-02, -9.08409777e-02,  2.93118420e-02,\n",
      "         7.23938311e-03, -2.82557882e-02, -1.16826307e-02,\n",
      "        -5.75325720e-02],\n",
      "       [-1.85874452e-02,  5.81003378e-02, -8.79108472e-02,\n",
      "        -2.04083365e-01,  2.18179140e-02, -5.21836686e-02,\n",
      "        -1.62033544e-01,  5.43069986e-02, -1.14751480e-01,\n",
      "         4.35309625e-03],\n",
      "       [ 1.26378288e-01, -3.19580066e-02,  8.68451985e-02,\n",
      "         4.02896478e-02,  5.96045480e-02,  5.87788110e-02,\n",
      "         1.12125313e-01,  1.92478297e-02,  9.32336081e-02,\n",
      "         7.51735063e-02],\n",
      "       [-6.66260528e-02,  1.90929027e-02, -1.15126633e-01,\n",
      "         1.72594179e-01,  1.72878803e-01, -1.69901808e-01,\n",
      "         1.44958609e-01,  1.39332700e-01, -1.62154754e-01,\n",
      "        -1.05318065e-01],\n",
      "       [ 7.35017226e-03, -8.64289139e-02, -8.90282318e-02,\n",
      "         2.38671178e-02, -3.24562453e-02,  8.81725331e-02,\n",
      "         3.24785597e-02, -8.93537555e-02,  1.58052239e-02,\n",
      "         3.63909909e-02],\n",
      "       [ 4.75308229e-02,  1.01839142e-01, -4.94103950e-02,\n",
      "         9.00560856e-02,  1.49092696e-01, -5.90590239e-02,\n",
      "        -1.42274280e-01,  1.06229063e-01,  1.00513581e-01,\n",
      "         1.17494696e-01],\n",
      "       [-1.37343514e-01,  1.51591633e-02, -8.05889004e-02,\n",
      "        -7.40203473e-02, -7.89044663e-02, -1.41834778e-01,\n",
      "        -2.47752818e-01,  8.50550044e-02, -9.64904142e-02,\n",
      "         5.07170745e-02],\n",
      "       [-6.10509109e-02,  5.19795866e-02,  9.00717482e-02,\n",
      "         9.58253377e-02,  7.89799535e-03,  6.48896880e-02,\n",
      "        -1.75704259e-02,  8.72850027e-02,  9.16874340e-02,\n",
      "        -6.11592080e-02],\n",
      "       [ 1.37752933e-01, -7.72207974e-02,  2.00217531e-01,\n",
      "         5.89832057e-02, -4.75240442e-02, -2.76822969e-02,\n",
      "        -4.99093753e-02, -1.84057536e-02, -5.98931784e-02,\n",
      "         2.93138588e-02],\n",
      "       [-7.86587092e-02,  1.30539415e-01,  2.28453385e-02,\n",
      "        -4.53338076e-02,  1.74663725e-02, -9.29516247e-02,\n",
      "         1.07504760e-01, -1.05821158e-01, -9.68633277e-02,\n",
      "         9.51349877e-03],\n",
      "       [ 1.40895551e-01, -1.54374155e-01,  9.20893981e-02,\n",
      "         7.27155324e-02,  1.56310413e-01,  1.42606377e-01,\n",
      "         6.48948118e-02,  1.44077633e-01,  7.42557912e-02,\n",
      "         1.59829219e-01],\n",
      "       [-1.23179718e-01,  5.13245262e-02, -4.60591102e-03,\n",
      "        -1.67404971e-01,  7.96414288e-02, -8.60908413e-02,\n",
      "        -1.17038440e-01, -1.28053933e-01, -5.58586269e-02,\n",
      "        -1.59333570e-02],\n",
      "       [-2.77057173e-02,  2.59650017e-03, -8.60191574e-03,\n",
      "         1.49670928e-02,  2.14800312e-02, -4.67531535e-02,\n",
      "        -7.97531114e-03, -4.35710125e-02,  7.07639999e-02,\n",
      "        -1.68652306e-02],\n",
      "       [ 1.13139458e-01,  2.07667713e-01,  2.09825161e-01,\n",
      "         7.03316495e-02, -4.08498213e-02, -4.61318811e-02,\n",
      "        -1.21778907e-01,  1.06338755e-02, -3.54020831e-02,\n",
      "         1.16037138e-01],\n",
      "       [-1.86738675e-01,  1.34521808e-01,  6.83640900e-02,\n",
      "        -2.21001964e-02,  1.07909768e-01,  7.30962115e-02,\n",
      "         1.04500520e-01,  1.07233993e-02,  4.63019112e-02,\n",
      "         2.91950034e-03],\n",
      "       [ 1.86122503e-01,  1.11404749e-01,  1.71069231e-01,\n",
      "         1.35500092e-01,  6.92902665e-02,  9.68471787e-02,\n",
      "         1.00104245e-01,  1.47066369e-01,  1.50707760e-01,\n",
      "         1.70385176e-01],\n",
      "       [-1.21987632e-01, -1.62169628e-01, -6.92121920e-02,\n",
      "         1.10170696e-01,  1.07711727e-01,  2.72057839e-03,\n",
      "         7.72611951e-03,  2.93551228e-02,  4.33064068e-02,\n",
      "         1.98946799e-02],\n",
      "       [-1.22512981e-01,  4.10252420e-02, -1.33529313e-01,\n",
      "         5.92810185e-02, -1.04937723e-01, -1.87285357e-01,\n",
      "         1.40772981e-01,  2.24549674e-02, -9.27887312e-02,\n",
      "         3.23874146e-03],\n",
      "       [ 1.11254290e-01,  1.30563456e-01,  1.36502803e-01,\n",
      "         6.51254047e-02,  1.91475724e-01,  1.19032741e-01,\n",
      "         1.22478149e-01,  1.31218577e-01,  6.94097237e-02,\n",
      "         5.84559480e-02],\n",
      "       [-1.23895456e-02,  6.59755415e-02,  8.73387349e-02,\n",
      "         1.53946087e-01, -5.91269326e-02,  5.34782865e-02,\n",
      "         3.48428843e-02,  1.14982767e-01,  8.20384819e-02,\n",
      "        -2.38383096e-02],\n",
      "       [ 1.30531198e-01,  1.12004893e-01,  1.12956959e-01,\n",
      "         7.82785627e-02,  4.72356316e-02, -9.56138509e-02,\n",
      "         2.02568006e-01, -1.31382274e-01,  6.72325220e-03,\n",
      "         3.14074912e-02],\n",
      "       [-7.05640060e-02,  6.08069339e-02, -4.91317329e-02,\n",
      "        -1.39806234e-02,  1.31940421e-01, -2.75316007e-02,\n",
      "        -3.62425773e-02,  9.43534805e-02, -2.71558222e-02,\n",
      "         1.16687638e-01],\n",
      "       [-4.31093650e-02,  7.23468728e-02, -1.28632249e-01,\n",
      "        -8.29960702e-02,  6.39897290e-02,  1.35900523e-01,\n",
      "        -5.74774027e-02,  3.54722357e-02, -1.17719707e-02,\n",
      "         1.29782540e-01],\n",
      "       [ 1.06934281e-02,  9.80899203e-03,  4.53338013e-03,\n",
      "         4.12476937e-02,  1.43322684e-02,  1.96391149e-02,\n",
      "         1.60618171e-02, -3.91343672e-02,  8.04524886e-02,\n",
      "         3.41904163e-02],\n",
      "       [-1.59674023e-01, -1.32517825e-01,  1.41143029e-01,\n",
      "        -1.49000857e-01,  1.07604981e-01,  8.67605573e-02,\n",
      "         8.08330412e-02, -1.13623960e-01, -1.11929425e-01,\n",
      "         1.41254494e-01],\n",
      "       [-2.56199801e-02, -2.28415667e-02,  9.15742437e-02,\n",
      "        -1.14835382e-01,  9.20859820e-02,  7.04090310e-02,\n",
      "        -3.81826626e-02,  3.54408592e-02, -7.11307098e-02,\n",
      "         1.56219205e-01],\n",
      "       [ 6.86828573e-02, -1.05873321e-01,  4.47225671e-02,\n",
      "        -6.28118050e-02, -9.15465953e-02, -9.64721659e-02,\n",
      "        -3.83421409e-03, -1.51260297e-01,  1.26756351e-01,\n",
      "         1.91405491e-01],\n",
      "       [-5.36681771e-02, -1.55875541e-01, -1.18277968e-01,\n",
      "        -1.19025151e-01, -2.04384033e-01, -8.44298705e-02,\n",
      "        -5.90739691e-02, -1.25834236e-01, -6.51172415e-02,\n",
      "        -2.32044248e-01],\n",
      "       [ 2.44494170e-03, -1.23214903e-02,  3.58916176e-02,\n",
      "         1.16849885e-01, -5.80267498e-02,  1.31069333e-01,\n",
      "        -8.21957551e-03,  6.67183880e-02, -1.39926136e-01,\n",
      "        -9.09480761e-02],\n",
      "       [-3.55232613e-02,  2.01887459e-03,  4.51775258e-02,\n",
      "         6.44527093e-02, -6.88422014e-02, -9.72868739e-02,\n",
      "        -1.34732555e-01, -2.82430826e-02, -8.00631149e-02,\n",
      "        -1.15346101e-01],\n",
      "       [ 1.12331376e-01,  6.34175725e-02, -5.61174785e-02,\n",
      "        -1.27657828e-01, -1.29723860e-02,  5.55206331e-02,\n",
      "         1.29678967e-01,  6.68587972e-02,  1.04615462e-02,\n",
      "        -8.19881391e-02],\n",
      "       [-1.24248019e-01,  1.74367204e-01, -1.17323130e-01,\n",
      "        -9.52410837e-02,  1.23210640e-01, -1.58015070e-01,\n",
      "        -3.26299227e-02, -1.16138776e-01, -1.63027256e-01,\n",
      "        -3.49594755e-02],\n",
      "       [ 1.22821170e-01,  2.26905230e-02,  1.91226781e-01,\n",
      "         1.07087565e-02,  1.44636654e-01, -3.64299252e-02,\n",
      "        -7.53520749e-02,  3.09399123e-02,  1.75583852e-01,\n",
      "         4.44480336e-02],\n",
      "       [-6.79328798e-02,  6.65901242e-02,  1.25596818e-01,\n",
      "         3.40639873e-02,  6.60242021e-02,  2.36959730e-02,\n",
      "        -1.73708758e-02, -5.92855695e-02, -3.18101617e-03,\n",
      "         4.18377677e-02],\n",
      "       [-9.23148479e-02, -5.47028939e-02,  6.73955850e-02,\n",
      "         1.02571090e-01,  9.57235560e-02,  1.43809036e-01,\n",
      "         1.34888173e-01, -1.79270937e-02, -6.10517636e-02,\n",
      "         6.65035659e-02],\n",
      "       [-8.05180893e-03, -1.46461086e-02, -4.05547091e-02,\n",
      "         7.14171598e-02,  1.30389124e-01, -1.02913269e-01,\n",
      "         1.09428166e-01, -1.21616030e-01, -2.58518899e-02,\n",
      "        -9.99679016e-02],\n",
      "       [ 6.30154662e-02, -2.40239353e-02,  1.54871337e-01,\n",
      "        -1.59710381e-01, -7.18389415e-02,  1.18827951e-01,\n",
      "         1.58325432e-01, -1.63553545e-01,  1.48335347e-01,\n",
      "        -1.01397790e-01],\n",
      "       [ 6.61733399e-02,  4.47312373e-02,  4.36442928e-02,\n",
      "         4.28785335e-02, -2.67948709e-02,  9.84305564e-02,\n",
      "        -1.18398801e-01,  1.18797870e-01,  1.18479747e-02,\n",
      "         2.12158029e-02],\n",
      "       [ 1.02586787e-01, -2.75450139e-02, -4.35024073e-02,\n",
      "        -1.64542721e-01, -5.53679770e-03, -7.30709286e-02,\n",
      "         1.71448681e-01,  9.82816059e-02, -8.68423942e-02,\n",
      "        -3.45949948e-03],\n",
      "       [-9.26928965e-02,  7.77350062e-05, -4.58889765e-02,\n",
      "        -7.49916714e-02,  1.65194179e-01, -6.98785193e-02,\n",
      "         8.24605918e-03, -1.76945064e-01,  7.84241839e-03,\n",
      "         1.33360598e-01],\n",
      "       [-4.89546357e-02, -5.49856272e-02, -1.13296496e-02,\n",
      "        -1.01850589e-01, -1.97764481e-01, -1.11283196e-01,\n",
      "        -9.36098440e-02, -1.12845076e-01, -8.37254711e-02,\n",
      "        -1.33428943e-01],\n",
      "       [ 1.58276190e-02, -9.18040377e-02,  1.45302373e-02,\n",
      "         4.61256227e-02, -1.57683570e-01,  4.89847630e-03,\n",
      "        -8.69815545e-02, -1.16361092e-01,  1.85385414e-03,\n",
      "         1.67180958e-01],\n",
      "       [-4.92195608e-02, -4.27731422e-02, -5.76897221e-02,\n",
      "         4.25898826e-02, -6.62737660e-03,  2.76310506e-02,\n",
      "        -1.61725736e-01, -4.72061603e-02, -4.10379773e-02,\n",
      "         1.94593247e-02],\n",
      "       [-3.15846031e-02,  2.24344737e-01, -2.44306200e-02,\n",
      "         7.25749317e-02, -1.69330464e-01,  1.46111345e-01,\n",
      "         7.41278540e-02,  4.99469026e-02, -5.67854019e-02,\n",
      "        -1.12004700e-01],\n",
      "       [ 3.71611914e-02,  4.39652338e-02,  9.12285906e-02,\n",
      "        -1.61737087e-01, -8.22414746e-02,  1.42981179e-01,\n",
      "        -5.42187203e-02, -1.03728797e-01, -4.28493492e-02,\n",
      "         2.21607273e-01],\n",
      "       [ 9.92376414e-02,  1.44611658e-01,  8.18642882e-02,\n",
      "         8.03612022e-02, -9.53757678e-02,  1.09594046e-01,\n",
      "         1.13532678e-01,  7.64633468e-02, -8.75988186e-03,\n",
      "        -4.54151023e-02],\n",
      "       [ 8.63897102e-02, -1.41072721e-01,  3.53639531e-02,\n",
      "        -7.32207463e-02,  9.52650599e-03, -1.05358965e-01,\n",
      "        -1.48193627e-02,  4.88360193e-02, -9.61490156e-02,\n",
      "         3.29595539e-02],\n",
      "       [ 4.52009825e-02, -7.41225709e-02, -1.77146287e-01,\n",
      "        -4.12955831e-02,  1.07465850e-02,  1.22547613e-01,\n",
      "         6.46203405e-03, -5.38444587e-02,  4.33859234e-02,\n",
      "         9.68006377e-03],\n",
      "       [-1.73829471e-02, -4.22193639e-02,  1.33671637e-02,\n",
      "        -3.46352473e-02,  9.76394721e-02,  3.06613108e-02,\n",
      "        -1.67895003e-02,  6.13623867e-02, -1.10419689e-02,\n",
      "         3.37416116e-02],\n",
      "       [-9.45273760e-03,  9.70923140e-02, -1.37973618e-01,\n",
      "        -5.94040342e-02, -3.70707393e-03,  2.02864171e-01,\n",
      "        -2.03362134e-01,  7.91187272e-02,  4.95878763e-02,\n",
      "        -1.51891494e-01]])]\n"
     ]
    }
   ],
   "source": [
    "print(clf.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clf.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[0].shape\n",
    "#explain the dimension of the W matrix for the first (hidden) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[4].shape\n",
    "#explain the dimension of the W matrix for the second (output) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercepts_[0].shape\n",
    "#explain the dimension of the b (bias) vector for the first (hidden) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercepts_[1].shape\n",
    "#explain the dimension of the b (bias) vector for the second (output) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:46:05.771427Z",
     "start_time": "2018-11-13T15:46:05.279063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99885"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T15:46:06.285050Z",
     "start_time": "2018-11-13T15:46:06.215576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( np.reshape( Xtest[1], (28,28) ) , cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(Xtest[1].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "Load MNIST fashion dataset, it has the same dimensions as MNIST dataset <br/>\n",
    "https://keras.io/api/datasets/fashion_mnist/  <br/> \n",
    "Go to the sklearn MLPClassifier website, learn about parameters and try different ones to achieve the \n",
    "best accuracy on the test set <br/>\n",
    "Comment on bias (overfitting) and variance (underfitting) <br/>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fashion_mnist.load_data()\n",
    "\n",
    "(Xtrain, ytrain), (Xtest, ytest) = dataset\n",
    "\n",
    "n_train = len(Xtrain)\n",
    "n_test = len(Xtest)\n",
    "\n",
    "n_features = 28*28\n",
    "\n",
    "Xtrain = Xtrain.reshape( n_train, n_features )\n",
    "Xtest  = Xtest.reshape( n_test, n_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow( np.reshape( Xtrain[5000], (28,28) ) , cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,50,25,10), max_iter=50,activation = 'tanh',\n",
    "                    solver='adam',random_state=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.18933755\n",
      "Iteration 2, loss = 0.83997346\n",
      "Iteration 3, loss = 0.80187300\n",
      "Iteration 4, loss = 0.76066321\n",
      "Iteration 5, loss = 0.76789468\n",
      "Iteration 6, loss = 0.73175515\n",
      "Iteration 7, loss = 0.74864025\n",
      "Iteration 8, loss = 0.74684676\n",
      "Iteration 9, loss = 0.76970043\n",
      "Iteration 10, loss = 0.73019225\n",
      "Iteration 11, loss = 0.69392482\n",
      "Iteration 12, loss = 0.71517872\n",
      "Iteration 13, loss = 0.71591268\n",
      "Iteration 14, loss = 0.71654923\n",
      "Iteration 15, loss = 0.67798672\n",
      "Iteration 16, loss = 0.68589243\n",
      "Iteration 17, loss = 0.67594368\n",
      "Iteration 18, loss = 0.67245901\n",
      "Iteration 19, loss = 0.65813810\n",
      "Iteration 20, loss = 0.66105805\n",
      "Iteration 21, loss = 0.68405609\n",
      "Iteration 22, loss = 0.67209643\n",
      "Iteration 23, loss = 0.64908035\n",
      "Iteration 24, loss = 0.66023584\n",
      "Iteration 25, loss = 0.70868791\n",
      "Iteration 26, loss = 0.66146557\n",
      "Iteration 27, loss = 0.65198242\n",
      "Iteration 28, loss = 0.68577464\n",
      "Iteration 29, loss = 0.64554093\n",
      "Iteration 30, loss = 0.66151554\n",
      "Iteration 31, loss = 0.66002791\n",
      "Iteration 32, loss = 0.64500416\n",
      "Iteration 33, loss = 0.62230757\n",
      "Iteration 34, loss = 0.62621696\n",
      "Iteration 35, loss = 0.65174395\n",
      "Iteration 36, loss = 0.62078922\n",
      "Iteration 37, loss = 0.60595106\n",
      "Iteration 38, loss = 0.63096458\n",
      "Iteration 39, loss = 0.68141874\n",
      "Iteration 40, loss = 0.67204285\n",
      "Iteration 41, loss = 0.64080585\n",
      "Iteration 42, loss = 0.63890526\n",
      "Iteration 43, loss = 0.61499496\n",
      "Iteration 44, loss = 0.61012985\n",
      "Iteration 45, loss = 0.61728782\n",
      "Iteration 46, loss = 0.63242710\n",
      "Iteration 47, loss = 0.63054816\n",
      "Iteration 48, loss = 0.62296418\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(100, 50, 25, 10),\n",
       "              max_iter=50, random_state=1, verbose=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7752166666666667"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7608"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(Xtest, ytest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
