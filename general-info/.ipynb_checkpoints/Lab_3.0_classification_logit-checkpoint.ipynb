{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 14pt;\">Prof. Krzysztof Rybinski</div><br/><br/>\n",
    "<div style=\"font-size: 22pt;\"><b>Artificial Intelligence course</b></div><br/><br/>\n",
    "<div style=\"font-size: 18pt;\">LAB 3</div><br/>\n",
    "<div style=\"font-size: 18pt;\">- Classification, logistic regression</div><br/>\n",
    "<div style=\"font-size: 18pt;\">- Train set, test set</div><br/>\n",
    "<div style=\"font-size: 18pt;\">- Confusion matrix</div><br/>\n",
    "<div style=\"font-size: 18pt;\">- Accuracy, other model quality metrics</div><br/>\n",
    "<div style=\"font-size: 18pt;\">- ROC curve, threshold selection</div><br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.graphics.api as smg\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check current folder\n",
    "os.chdir(\"../Python\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and inspect KPI data\n",
    "kpi = pd.read_csv(\"data/KPI_data_for_logit_model.csv\")\n",
    "kpi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns that we will use\n",
    "kpi = kpi[['KPI_assessment_1', 'Number.of.questionnaires_1', 'Average_grade_1', \\\n",
    "           'NPS_1', 'Additional_achievement_1', 'X502010_1']]\n",
    "kpi.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 14pt;\">Exercise 1</div>\n",
    "Estimate logistic regression model from lecture 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for multicollinearity\n",
    "corr = kpi.corr()\n",
    "smg.plot_corr(corr, xnames=corr.columns.values)\n",
    "smg.plot_corr(corr, xnames=corr.columns.values, normcolor=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate the model using robust standard errors\n",
    "y502010 = kpi[['X502010_1']]\n",
    "X = kpi.drop(['X502010_1'], axis=1)\n",
    "X = sm.add_constant(X)\n",
    "model_kpi_sm = sm.Logit(y502010, X)\n",
    "res_kpi_sm = model_kpi_sm.fit(method='newton', cov_type=\"hc0\")\n",
    "res_kpi_sm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 14pt;\">Exercise 2</div>\n",
    "Implement ML approach to classification problem\n",
    "Create train and test sets, train the model, make predicitons on test set, calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we implement machine learning approach to classification \n",
    "#split the data into train and test set\n",
    "X = X.drop(['const'], axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y502010, test_size=0.2, random_state=4, stratify=y502010)\n",
    "\n",
    "#check proportions on 1s\n",
    "y_train.mean(), y_test.mean()\n",
    "\n",
    "#what is the base model accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model to the train data\n",
    "model_kpi = LogisticRegression(random_state=100)\n",
    "model_kpi.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['X502010_1'].ravel()\n",
    "y_test = y_test['X502010_1'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kpi.fit(x_train, y_train)\n",
    "model_kpi.coef_, model_kpi.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate predictions\n",
    "y_pred=model_kpi.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute and plot confussion matrix\n",
    "cfm = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "cfm = cfm / cfm.sum().sum()\n",
    "sns.heatmap(cfm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate accuracy\n",
    "accuracy = cfm.iloc[0,0] + cfm.iloc[1,1]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print sklearn clasification report\n",
    "target_names = ['no raise', 'wage raise']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#improve the model by using ROC curve to calculate threshold\n",
    "#get probabilities for y_pred\n",
    "y_prob = model_kpi.predict_proba(x_test)\n",
    "y_prob = y_prob[:,1]\n",
    "print(y_pred, '\\n', y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape, y_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tpr, fpr and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "str_thresholds = [str(round(x,2)) for x in thresholds]\n",
    "print(fpr, '\\n', tpr, '\\n', str_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change every second threshold to dot\n",
    "sel = list(range(len(str_thresholds))[::2])\n",
    "for ind in sel:\n",
    "    str_thresholds[ind] = '.'\n",
    "print(str_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "\n",
    "for i in range(len(thresholds)): \n",
    "    plt.text(fpr[i], tpr[i], str_thresholds[i], fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate ROC AUC (area under curve)\n",
    "roc_auc_score(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect confusion matrix for different threshold values\n",
    "\n",
    "############################################################\n",
    "def calculate_confusion_matrix(y_test, y_prob, threshold):\n",
    "    y_pred_t = 1*(y_prob >= threshold)\n",
    "    cfm = pd.crosstab(y_test, y_pred_t, rownames=['Actual'], colnames=['Predicted'])\n",
    "    cfm = cfm / cfm.sum().sum()\n",
    "    sns.heatmap(cfm, annot=True)\n",
    "    accuracy = cfm.iloc[0,0] + cfm.iloc[1,1]\n",
    "    print(\"`Accuracy =  {:6.4f}\".format(accuracy))\n",
    "    return cfm, accuracy\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try different thresholds, comment on changes in confussion matrix\n",
    "cfm , accuracy = calculate_confusion_matrix(y_test, y_prob, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sklearn function to compute confusion matrix\n",
    "cfm2 = confusion_matrix(y_test, y_pred)\n",
    "cfm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm2/cfm2.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
